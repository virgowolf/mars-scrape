{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 12 Challenge\n",
    "## Deliverable 1: Scrape Titles and Preview Text from Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Splinter and BeautifulSoup\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "browser = Browser('chrome')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Visit the Website\n",
    "\n",
    "1. Use automated browsing to visit the [Mars news site](https://static.bc-edx.com/data/web/mars_news/index.html). Inspect the page to identify which elements to scrape.\n",
    "\n",
    "      > **Hint** To identify which elements to scrape, you might want to inspect the page by using Chrome DevTools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the Mars news site\n",
    "url = 'https://static.bc-edx.com/data/web/mars_news/index.html'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Scrape the Website\n",
    "\n",
    "Create a Beautiful Soup object and use it to extract text elements from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Beautiful Soup object\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News - Mars Exploration Program\n",
      "MARS Planet Science\n",
      "Exploration Program\n",
      "The Red Planet\n",
      "The Program\n",
      "News & Events\n",
      "Multimedia\n",
      "Missions\n",
      "More\n",
      "News\n",
      "Latest\n",
      "All Categories\n",
      "November 9, 2022\n",
      "NASA's MAVEN Observes Martian Light Show Caused by Major Solar Storm\n",
      "For the first time in its eight years orbiting Mars, NASA’s MAVEN mission witnessed two different types of ultraviolet aurorae simultaneously, the result of solar storms that began on Aug. 27.\n",
      "November 1, 2022\n",
      "NASA Prepares to Say 'Farewell' to InSight Spacecraft\n",
      "A closer look at what goes into wrapping up the mission as the spacecraft’s power supply continues to dwindle.\n",
      "October 28, 2022\n",
      "NASA and ESA Agree on Next Steps to Return Mars Samples to Earth\n",
      "The agency’s Perseverance rover will establish the first sample depot on Mars.\n",
      "October 27, 2022\n",
      "NASA's InSight Lander Detects Stunning Meteoroid Impact on Mars\n",
      "The agency’s lander felt the ground shake during the impact while cameras aboard the Mars Reconnaissance Orbiter spotted the yawning new crater from space.\n",
      "October 21, 2022\n",
      "NASA To Host Briefing on InSight, Mars Reconnaissance Orbiter Findings\n",
      "Scientists from two Mars missions will discuss how they combined images and data for a major finding on the Red Planet.\n",
      "October 20, 2022\n",
      "Why NASA Is Trying To Crash Land on Mars\n",
      "Like a car’s crumple zone, the experimental SHIELD lander is designed to absorb a hard impact.\n",
      "October 19, 2022\n",
      "Curiosity Mars Rover Reaches Long-Awaited Salty Region\n",
      "After years of climbing, the Mars rover has arrived at a special region believed to have formed as Mars’ climate was drying.\n",
      "October 12, 2022\n",
      "Mars Mission Shields Up for Tests\n",
      "Protecting Mars Sample Return spacecraft from micrometeorites requires high-caliber work.\n",
      "October 7, 2022\n",
      "NASA's InSight Waits Out Dust Storm\n",
      "InSight’s team is taking steps to help the solar-powered lander continue operating for as long as possible.\n",
      "September 19, 2022\n",
      "NASA's InSight 'Hears' Its First Meteoroid Impacts on Mars\n",
      "The Mars lander’s seismometer has picked up vibrations from four separate impacts in the past two years.\n",
      "September 15, 2022\n",
      "NASA's Perseverance Rover Investigates Geologically Rich Mars Terrain\n",
      "The latest findings provide greater detail on a region of the Red Planet that has a watery past and is yielding promising samples for the NASA-ESA Mars Sample Return campaign.\n",
      "September 12, 2022\n",
      "NASA to Host Briefing on Perseverance Mars Rover Mission Operations\n",
      "Members of the mission will discuss the rover’s activities as it gathers samples in an ancient river delta.\n",
      "August 25, 2022\n",
      "NASA's Perseverance Makes New Discoveries in Mars' Jezero Crater\n",
      "The rover found that Jezero Crater’s floor is made up of volcanic rocks that have interacted with water.\n",
      "August 5, 2022\n",
      "10 Years Since Landing, NASA's Curiosity Mars Rover Still Has Drive\n",
      "Despite signs of wear, the intrepid spacecraft is about to start an exciting new chapter of its mission as it climbs a Martian mountain.\n",
      "August 4, 2022\n",
      "SAM's Top 5 Discoveries Aboard NASA's Curiosity Rover at Mars\n",
      "“Selfie” of the Curiosity rover with inset showing the SAM instrument prior to installation on the rover.\n",
      "More\n",
      "You Might Also Like\n",
      "NASA Marks 25 Years Since Pathfinder Touched Down on Mars\n",
      "NASA's Perseverance Rover Captures Video of Solar Eclipse on Mars\n",
      "NASA, UAE Mars Missions Agree to Share Science Data\n",
      "The Red Planet\n",
      "Dashboard\n",
      "Science Goals\n",
      "The Planet\n",
      "The Program\n",
      "Mission Statement\n",
      "About the Program\n",
      "Organization Why Mars?\n",
      "Multimedia\n",
      "Images\n",
      "Videos\n",
      "More Resources\n",
      "Missions\n",
      "Past\n",
      "Present\n",
      "Future\n",
      "Images and news content extracted from NASA's\n",
      "Mars News\n",
      "website on November 9, 2022.\n",
      "Images used in accordance with the\n",
      "JPL Image Use Policy\n",
      ".\n",
      "This site is operated by edX Boot Camps LLC for educational purposes only.\n",
      "This is not a website endorsed by NASA. This website is intended only for internal academic purposes.\n"
     ]
    }
   ],
   "source": [
    "# Extract all the text elements\n",
    "text_elem = soup.find_all(string = True)\n",
    "\n",
    "# Extract text content from text elements\n",
    "text_content = [element.strip() for element in text_elem if element.strip()]\n",
    "\n",
    "# Print or process the extracted text\n",
    "for text in text_content:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Store the Results\n",
    "\n",
    "Extract the titles and preview text of the news articles that you scraped. Store the scraping results in Python data structures as follows:\n",
    "\n",
    "* Store each title-and-preview pair in a Python dictionary. And, give each dictionary two keys: `title` and `preview`. An example is the following:\n",
    "\n",
    "  ```python\n",
    "  {'title': \"NASA's MAVEN Observes Martian Light Show Caused by Major Solar Storm\", \n",
    "   'preview': \"For the first time in its eight years orbiting Mars, NASA’s MAVEN mission witnessed two different types of ultraviolet aurorae simultaneously, the result of solar storms that began on Aug. 27.\"\n",
    "  }\n",
    "  ```\n",
    "\n",
    "* Store all the dictionaries in a Python list.\n",
    "\n",
    "* Print the list in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to perform the web scraping\n",
    "def get_preview():\n",
    "    # Collect the HTML from the browser\n",
    "    html = browser.html\n",
    "    \n",
    "    # Parse the HTML with Beautiful Soup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Save the title-preview area of the web page to a variable\n",
    "    preview_area = soup.find(\"div\", class_=\"list_text\")\n",
    "\n",
    "    text_elements = preview_area.find_all(\"div\", class_ \"article_teaser_body\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the dictionaries\n",
    "dict_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "find() takes no keyword arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Loop through the text elements\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m text_elem:\n\u001b[1;32m      3\u001b[0m     \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Extract the title and preview text from the elements\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     title \u001b[38;5;241m=\u001b[39m \u001b[43melement\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdiv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent-title\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m      6\u001b[0m     preview \u001b[38;5;241m=\u001b[39m element\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticle_teaser_body\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Store each title and preview pair in a dictionary\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: find() takes no keyword arguments"
     ]
    }
   ],
   "source": [
    "# Loop through the text elements\n",
    "for element in text_elements:\n",
    "    \n",
    "# Extract the title and preview text from the elements\n",
    "    title = element.find(\"div\", class_ = \"content-title\").text.strip()\n",
    "    preview = element.find(\"div\", class_ = \"article_teaser_body\").text.strip()\n",
    "\n",
    "# Store each title and preview pair in a dictionary\n",
    "preview_dict = {\n",
    "    \"title\": title,\n",
    "    \"preview\": preview\n",
    "}\n",
    "# Append the dictionary to the list\n",
    "dict_list.append(preview_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the list to confirm success\n",
    "return dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
